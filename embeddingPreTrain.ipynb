{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "expected-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# 引入attribute向量\n",
    "def get_data():\n",
    "    attribute_embedding = np.load('generateData/Attribute_Embedding.npy')\n",
    "    attribute_matrix = torch.from_numpy(attribute_embedding)\n",
    "    torch_dataset = Data.TensorDataset(attribute_matrix)\n",
    "    data_loader = Data.DataLoader(dataset=torch_dataset, batch_size=32)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outer-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(AE, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "                        nn.Linear(self.input_dim, 32),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(32, self.encoding_dim))\n",
    "        self.decoder = nn.Sequential(\n",
    "                        nn.Linear(self.encoding_dim, 32),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(32, self.input_dim))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        m = self.encoder(input)\n",
    "        out = self.decoder(m)\n",
    "        return m, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "shared-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_penalty(var):\n",
    "    return torch.abs(var).sum()\n",
    "\n",
    "\n",
    "input_dim = 61\n",
    "encoding_dim = 16\n",
    "model = AE(input_dim, encoding_dim)\n",
    "    \n",
    "def train():  \n",
    "    save_path = \"generateData/AE.pkl\"\n",
    "    lr = 1e-2\n",
    "    epoches = 20\n",
    "    weight_decay = 1e-5\n",
    "\n",
    "    train_data = get_data()\n",
    "    loss_score = 100\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    for epoch in range(epoches):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, data in enumerate(train_data):\n",
    "            inputs = Variable(data[0])\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            mid_reps, outputs = model(inputs)\n",
    "            mse_loss = F.mse_loss(outputs, inputs)\n",
    "            l1_reg = weight_decay*l1_penalty(mid_reps)\n",
    "            loss = mse_loss + l1_reg\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if batch_idx%50 == 49:\n",
    "                print('Train Epoch: %d, Batch %d, loss:%.6f' % (epoch+1, (batch_idx+1)/50, running_loss/100))\n",
    "                if save_path and running_loss<loss_score:\n",
    "                    loss_score = running_loss\n",
    "                    torch.save(model, save_path)\n",
    "                    print(\"******Save model successful******\")\n",
    "                running_loss = 0.0\n",
    "            \n",
    "            \n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "satisfactory-adelaide",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1, Batch 1, loss:0.061869\n",
      "******Save model successful******\n",
      "Train Epoch: 1, Batch 2, loss:0.035895\n",
      "******Save model successful******\n",
      "Train Epoch: 1, Batch 3, loss:0.028323\n",
      "******Save model successful******\n",
      "Train Epoch: 1, Batch 4, loss:0.022615\n",
      "******Save model successful******\n",
      "Train Epoch: 1, Batch 5, loss:0.020680\n",
      "******Save model successful******\n",
      "Train Epoch: 1, Batch 6, loss:0.019655\n",
      "******Save model successful******\n",
      "Train Epoch: 1, Batch 7, loss:0.018477\n",
      "******Save model successful******\n",
      "Train Epoch: 1, Batch 8, loss:0.017275\n",
      "******Save model successful******\n",
      "Train Epoch: 1, Batch 9, loss:0.016322\n",
      "******Save model successful******\n",
      "Train Epoch: 1, Batch 10, loss:0.014579\n",
      "******Save model successful******\n",
      "Train Epoch: 1, Batch 11, loss:0.014161\n",
      "******Save model successful******\n",
      "Train Epoch: 1, Batch 12, loss:0.013559\n",
      "******Save model successful******\n",
      "Train Epoch: 1, Batch 13, loss:0.013124\n",
      "******Save model successful******\n",
      "Train Epoch: 2, Batch 1, loss:0.020446\n",
      "Train Epoch: 2, Batch 2, loss:0.015972\n",
      "Train Epoch: 2, Batch 3, loss:0.015128\n",
      "Train Epoch: 2, Batch 4, loss:0.013758\n",
      "Train Epoch: 2, Batch 5, loss:0.014260\n",
      "Train Epoch: 2, Batch 6, loss:0.014369\n",
      "Train Epoch: 2, Batch 7, loss:0.014441\n",
      "Train Epoch: 2, Batch 8, loss:0.013896\n",
      "Train Epoch: 2, Batch 9, loss:0.014091\n",
      "Train Epoch: 2, Batch 10, loss:0.012950\n",
      "******Save model successful******\n",
      "Train Epoch: 2, Batch 11, loss:0.012837\n",
      "******Save model successful******\n",
      "Train Epoch: 2, Batch 12, loss:0.012841\n",
      "Train Epoch: 2, Batch 13, loss:0.012491\n",
      "******Save model successful******\n",
      "Train Epoch: 3, Batch 1, loss:0.019639\n",
      "Train Epoch: 3, Batch 2, loss:0.015176\n",
      "Train Epoch: 3, Batch 3, loss:0.014546\n",
      "Train Epoch: 3, Batch 4, loss:0.012884\n",
      "Train Epoch: 3, Batch 5, loss:0.013590\n",
      "Train Epoch: 3, Batch 6, loss:0.013508\n",
      "Train Epoch: 3, Batch 7, loss:0.013507\n",
      "Train Epoch: 3, Batch 8, loss:0.013012\n",
      "Train Epoch: 3, Batch 9, loss:0.013540\n",
      "Train Epoch: 3, Batch 10, loss:0.012167\n",
      "******Save model successful******\n",
      "Train Epoch: 3, Batch 11, loss:0.011949\n",
      "******Save model successful******\n",
      "Train Epoch: 3, Batch 12, loss:0.011880\n",
      "******Save model successful******\n",
      "Train Epoch: 3, Batch 13, loss:0.011717\n",
      "******Save model successful******\n",
      "Train Epoch: 4, Batch 1, loss:0.018738\n",
      "Train Epoch: 4, Batch 2, loss:0.013873\n",
      "Train Epoch: 4, Batch 3, loss:0.013232\n",
      "Train Epoch: 4, Batch 4, loss:0.011530\n",
      "******Save model successful******\n",
      "Train Epoch: 4, Batch 5, loss:0.012561\n",
      "Train Epoch: 4, Batch 6, loss:0.012960\n",
      "Train Epoch: 4, Batch 7, loss:0.012996\n",
      "Train Epoch: 4, Batch 8, loss:0.012058\n",
      "Train Epoch: 4, Batch 9, loss:0.012596\n",
      "Train Epoch: 4, Batch 10, loss:0.011677\n",
      "Train Epoch: 4, Batch 11, loss:0.012132\n",
      "Train Epoch: 4, Batch 12, loss:0.011332\n",
      "******Save model successful******\n",
      "Train Epoch: 4, Batch 13, loss:0.011126\n",
      "******Save model successful******\n",
      "Train Epoch: 5, Batch 1, loss:0.017899\n",
      "Train Epoch: 5, Batch 2, loss:0.013373\n",
      "Train Epoch: 5, Batch 3, loss:0.012973\n",
      "Train Epoch: 5, Batch 4, loss:0.011463\n",
      "Train Epoch: 5, Batch 5, loss:0.012149\n",
      "Train Epoch: 5, Batch 6, loss:0.012492\n",
      "Train Epoch: 5, Batch 7, loss:0.012696\n",
      "Train Epoch: 5, Batch 8, loss:0.011985\n",
      "Train Epoch: 5, Batch 9, loss:0.012358\n",
      "Train Epoch: 5, Batch 10, loss:0.011295\n",
      "Train Epoch: 5, Batch 11, loss:0.011355\n",
      "Train Epoch: 5, Batch 12, loss:0.011255\n",
      "Train Epoch: 5, Batch 13, loss:0.011062\n",
      "******Save model successful******\n",
      "Train Epoch: 6, Batch 1, loss:0.018224\n",
      "Train Epoch: 6, Batch 2, loss:0.013620\n",
      "Train Epoch: 6, Batch 3, loss:0.013070\n",
      "Train Epoch: 6, Batch 4, loss:0.011328\n",
      "Train Epoch: 6, Batch 5, loss:0.012071\n",
      "Train Epoch: 6, Batch 6, loss:0.012275\n",
      "Train Epoch: 6, Batch 7, loss:0.012620\n",
      "Train Epoch: 6, Batch 8, loss:0.011657\n",
      "Train Epoch: 6, Batch 9, loss:0.012300\n",
      "Train Epoch: 6, Batch 10, loss:0.011200\n",
      "Train Epoch: 6, Batch 11, loss:0.010795\n",
      "******Save model successful******\n",
      "Train Epoch: 6, Batch 12, loss:0.010719\n",
      "******Save model successful******\n",
      "Train Epoch: 6, Batch 13, loss:0.010721\n",
      "Train Epoch: 7, Batch 1, loss:0.018511\n",
      "Train Epoch: 7, Batch 2, loss:0.013872\n",
      "Train Epoch: 7, Batch 3, loss:0.012901\n",
      "Train Epoch: 7, Batch 4, loss:0.011087\n",
      "Train Epoch: 7, Batch 5, loss:0.011653\n",
      "Train Epoch: 7, Batch 6, loss:0.011855\n",
      "Train Epoch: 7, Batch 7, loss:0.012087\n",
      "Train Epoch: 7, Batch 8, loss:0.011300\n",
      "Train Epoch: 7, Batch 9, loss:0.011638\n",
      "Train Epoch: 7, Batch 10, loss:0.010389\n",
      "******Save model successful******\n",
      "Train Epoch: 7, Batch 11, loss:0.010249\n",
      "******Save model successful******\n",
      "Train Epoch: 7, Batch 12, loss:0.010361\n",
      "Train Epoch: 7, Batch 13, loss:0.010773\n",
      "Train Epoch: 8, Batch 1, loss:0.017121\n",
      "Train Epoch: 8, Batch 2, loss:0.012893\n",
      "Train Epoch: 8, Batch 3, loss:0.012375\n",
      "Train Epoch: 8, Batch 4, loss:0.010605\n",
      "Train Epoch: 8, Batch 5, loss:0.011294\n",
      "Train Epoch: 8, Batch 6, loss:0.011507\n",
      "Train Epoch: 8, Batch 7, loss:0.011763\n",
      "Train Epoch: 8, Batch 8, loss:0.011160\n",
      "Train Epoch: 8, Batch 9, loss:0.011449\n",
      "Train Epoch: 8, Batch 10, loss:0.010338\n",
      "Train Epoch: 8, Batch 11, loss:0.010239\n",
      "******Save model successful******\n",
      "Train Epoch: 8, Batch 12, loss:0.010139\n",
      "******Save model successful******\n",
      "Train Epoch: 8, Batch 13, loss:0.010023\n",
      "******Save model successful******\n",
      "Train Epoch: 9, Batch 1, loss:0.017392\n",
      "Train Epoch: 9, Batch 2, loss:0.012987\n",
      "Train Epoch: 9, Batch 3, loss:0.012104\n",
      "Train Epoch: 9, Batch 4, loss:0.010344\n",
      "Train Epoch: 9, Batch 5, loss:0.011097\n",
      "Train Epoch: 9, Batch 6, loss:0.011312\n",
      "Train Epoch: 9, Batch 7, loss:0.011363\n",
      "Train Epoch: 9, Batch 8, loss:0.010811\n",
      "Train Epoch: 9, Batch 9, loss:0.011080\n",
      "Train Epoch: 9, Batch 10, loss:0.010007\n",
      "******Save model successful******\n",
      "Train Epoch: 9, Batch 11, loss:0.009746\n",
      "******Save model successful******\n",
      "Train Epoch: 9, Batch 12, loss:0.009713\n",
      "******Save model successful******\n",
      "Train Epoch: 9, Batch 13, loss:0.009914\n",
      "Train Epoch: 10, Batch 1, loss:0.016357\n",
      "Train Epoch: 10, Batch 2, loss:0.012537\n",
      "Train Epoch: 10, Batch 3, loss:0.012030\n",
      "Train Epoch: 10, Batch 4, loss:0.010492\n",
      "Train Epoch: 10, Batch 5, loss:0.010944\n",
      "Train Epoch: 10, Batch 6, loss:0.010761\n",
      "Train Epoch: 10, Batch 7, loss:0.011077\n",
      "Train Epoch: 10, Batch 8, loss:0.010861\n",
      "Train Epoch: 10, Batch 9, loss:0.010931\n",
      "Train Epoch: 10, Batch 10, loss:0.009783\n",
      "Train Epoch: 10, Batch 11, loss:0.009471\n",
      "******Save model successful******\n",
      "Train Epoch: 10, Batch 12, loss:0.009434\n",
      "******Save model successful******\n",
      "Train Epoch: 10, Batch 13, loss:0.009910\n",
      "Train Epoch: 11, Batch 1, loss:0.016568\n",
      "Train Epoch: 11, Batch 2, loss:0.011939\n",
      "Train Epoch: 11, Batch 3, loss:0.011183\n",
      "Train Epoch: 11, Batch 4, loss:0.009570\n",
      "Train Epoch: 11, Batch 5, loss:0.010235\n",
      "Train Epoch: 11, Batch 6, loss:0.010027\n",
      "Train Epoch: 11, Batch 7, loss:0.010411\n",
      "Train Epoch: 11, Batch 8, loss:0.009549\n",
      "Train Epoch: 11, Batch 9, loss:0.009982\n",
      "Train Epoch: 11, Batch 10, loss:0.008879\n",
      "******Save model successful******\n",
      "Train Epoch: 11, Batch 11, loss:0.008844\n",
      "******Save model successful******\n",
      "Train Epoch: 11, Batch 12, loss:0.008835\n",
      "******Save model successful******\n",
      "Train Epoch: 11, Batch 13, loss:0.008959\n",
      "Train Epoch: 12, Batch 1, loss:0.016033\n",
      "Train Epoch: 12, Batch 2, loss:0.011520\n",
      "Train Epoch: 12, Batch 3, loss:0.010475\n",
      "Train Epoch: 12, Batch 4, loss:0.008927\n",
      "Train Epoch: 12, Batch 5, loss:0.009634\n",
      "Train Epoch: 12, Batch 6, loss:0.009721\n",
      "Train Epoch: 12, Batch 7, loss:0.010108\n",
      "Train Epoch: 12, Batch 8, loss:0.009057\n",
      "Train Epoch: 12, Batch 9, loss:0.009493\n",
      "Train Epoch: 12, Batch 10, loss:0.008537\n",
      "******Save model successful******\n",
      "Train Epoch: 12, Batch 11, loss:0.008301\n",
      "******Save model successful******\n",
      "Train Epoch: 12, Batch 12, loss:0.008574\n",
      "Train Epoch: 12, Batch 13, loss:0.008828\n",
      "Train Epoch: 13, Batch 1, loss:0.015582\n",
      "Train Epoch: 13, Batch 2, loss:0.011337\n",
      "Train Epoch: 13, Batch 3, loss:0.010483\n",
      "Train Epoch: 13, Batch 4, loss:0.008832\n",
      "Train Epoch: 13, Batch 5, loss:0.009390\n",
      "Train Epoch: 13, Batch 6, loss:0.009436\n",
      "Train Epoch: 13, Batch 7, loss:0.009842\n",
      "Train Epoch: 13, Batch 8, loss:0.008966\n",
      "Train Epoch: 13, Batch 9, loss:0.009422\n",
      "Train Epoch: 13, Batch 10, loss:0.008427\n",
      "Train Epoch: 13, Batch 11, loss:0.008265\n",
      "******Save model successful******\n",
      "Train Epoch: 13, Batch 12, loss:0.008614\n",
      "Train Epoch: 13, Batch 13, loss:0.008596\n",
      "Train Epoch: 14, Batch 1, loss:0.015428\n",
      "Train Epoch: 14, Batch 2, loss:0.011061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14, Batch 3, loss:0.010191\n",
      "Train Epoch: 14, Batch 4, loss:0.009053\n",
      "Train Epoch: 14, Batch 5, loss:0.009353\n",
      "Train Epoch: 14, Batch 6, loss:0.009318\n",
      "Train Epoch: 14, Batch 7, loss:0.009658\n",
      "Train Epoch: 14, Batch 8, loss:0.008739\n",
      "Train Epoch: 14, Batch 9, loss:0.009214\n",
      "Train Epoch: 14, Batch 10, loss:0.008282\n",
      "Train Epoch: 14, Batch 11, loss:0.008011\n",
      "******Save model successful******\n",
      "Train Epoch: 14, Batch 12, loss:0.008252\n",
      "Train Epoch: 14, Batch 13, loss:0.008428\n",
      "Train Epoch: 15, Batch 1, loss:0.016029\n",
      "Train Epoch: 15, Batch 2, loss:0.011128\n",
      "Train Epoch: 15, Batch 3, loss:0.010104\n",
      "Train Epoch: 15, Batch 4, loss:0.008725\n",
      "Train Epoch: 15, Batch 5, loss:0.009298\n",
      "Train Epoch: 15, Batch 6, loss:0.009391\n",
      "Train Epoch: 15, Batch 7, loss:0.009696\n",
      "Train Epoch: 15, Batch 8, loss:0.008726\n",
      "Train Epoch: 15, Batch 9, loss:0.009204\n",
      "Train Epoch: 15, Batch 10, loss:0.008230\n",
      "Train Epoch: 15, Batch 11, loss:0.008051\n",
      "Train Epoch: 15, Batch 12, loss:0.008330\n",
      "Train Epoch: 15, Batch 13, loss:0.008357\n",
      "Train Epoch: 16, Batch 1, loss:0.015082\n",
      "Train Epoch: 16, Batch 2, loss:0.010450\n",
      "Train Epoch: 16, Batch 3, loss:0.010145\n",
      "Train Epoch: 16, Batch 4, loss:0.008787\n",
      "Train Epoch: 16, Batch 5, loss:0.009173\n",
      "Train Epoch: 16, Batch 6, loss:0.009271\n",
      "Train Epoch: 16, Batch 7, loss:0.009531\n",
      "Train Epoch: 16, Batch 8, loss:0.008591\n",
      "Train Epoch: 16, Batch 9, loss:0.008958\n",
      "Train Epoch: 16, Batch 10, loss:0.007944\n",
      "******Save model successful******\n",
      "Train Epoch: 16, Batch 11, loss:0.007933\n",
      "******Save model successful******\n",
      "Train Epoch: 16, Batch 12, loss:0.008173\n",
      "Train Epoch: 16, Batch 13, loss:0.008210\n",
      "Train Epoch: 17, Batch 1, loss:0.014722\n",
      "Train Epoch: 17, Batch 2, loss:0.010283\n",
      "Train Epoch: 17, Batch 3, loss:0.009655\n",
      "Train Epoch: 17, Batch 4, loss:0.008178\n",
      "Train Epoch: 17, Batch 5, loss:0.008949\n",
      "Train Epoch: 17, Batch 6, loss:0.008981\n",
      "Train Epoch: 17, Batch 7, loss:0.009250\n",
      "Train Epoch: 17, Batch 8, loss:0.008277\n",
      "Train Epoch: 17, Batch 9, loss:0.008783\n",
      "Train Epoch: 17, Batch 10, loss:0.008104\n",
      "Train Epoch: 17, Batch 11, loss:0.008214\n",
      "Train Epoch: 17, Batch 12, loss:0.007931\n",
      "******Save model successful******\n",
      "Train Epoch: 17, Batch 13, loss:0.008126\n",
      "Train Epoch: 18, Batch 1, loss:0.014244\n",
      "Train Epoch: 18, Batch 2, loss:0.010360\n",
      "Train Epoch: 18, Batch 3, loss:0.009699\n",
      "Train Epoch: 18, Batch 4, loss:0.008132\n",
      "Train Epoch: 18, Batch 5, loss:0.009219\n",
      "Train Epoch: 18, Batch 6, loss:0.009184\n",
      "Train Epoch: 18, Batch 7, loss:0.009442\n",
      "Train Epoch: 18, Batch 8, loss:0.008404\n",
      "Train Epoch: 18, Batch 9, loss:0.008789\n",
      "Train Epoch: 18, Batch 10, loss:0.007921\n",
      "******Save model successful******\n",
      "Train Epoch: 18, Batch 11, loss:0.007717\n",
      "******Save model successful******\n",
      "Train Epoch: 18, Batch 12, loss:0.007911\n",
      "Train Epoch: 18, Batch 13, loss:0.007919\n",
      "Train Epoch: 19, Batch 1, loss:0.014126\n",
      "Train Epoch: 19, Batch 2, loss:0.010176\n",
      "Train Epoch: 19, Batch 3, loss:0.009666\n",
      "Train Epoch: 19, Batch 4, loss:0.008301\n",
      "Train Epoch: 19, Batch 5, loss:0.008937\n",
      "Train Epoch: 19, Batch 6, loss:0.009033\n",
      "Train Epoch: 19, Batch 7, loss:0.009395\n",
      "Train Epoch: 19, Batch 8, loss:0.008382\n",
      "Train Epoch: 19, Batch 9, loss:0.008980\n",
      "Train Epoch: 19, Batch 10, loss:0.007941\n",
      "Train Epoch: 19, Batch 11, loss:0.007837\n",
      "Train Epoch: 19, Batch 12, loss:0.007866\n",
      "Train Epoch: 19, Batch 13, loss:0.008024\n",
      "Train Epoch: 20, Batch 1, loss:0.014267\n",
      "Train Epoch: 20, Batch 2, loss:0.010321\n",
      "Train Epoch: 20, Batch 3, loss:0.009676\n",
      "Train Epoch: 20, Batch 4, loss:0.008356\n",
      "Train Epoch: 20, Batch 5, loss:0.008998\n",
      "Train Epoch: 20, Batch 6, loss:0.009023\n",
      "Train Epoch: 20, Batch 7, loss:0.009174\n",
      "Train Epoch: 20, Batch 8, loss:0.008243\n",
      "Train Epoch: 20, Batch 9, loss:0.008857\n",
      "Train Epoch: 20, Batch 10, loss:0.007812\n",
      "Train Epoch: 20, Batch 11, loss:0.007793\n",
      "Train Epoch: 20, Batch 12, loss:0.007985\n",
      "Train Epoch: 20, Batch 13, loss:0.008068\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cosmetic-pizza",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "test_loader = get_data()\n",
    "for batch_idx, data in enumerate(test_loader):\n",
    "    inputs = Variable(data[0])\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = inputs.cuda()\n",
    "    mid_rep, out = model(inputs)\n",
    "    highLevel_representation = mid_rep.data.cpu().numpy()\n",
    "    if batch_idx == 0:\n",
    "        attribute_embedding_high = highLevel_representation\n",
    "    else:\n",
    "        attribute_embedding_high = np.concatenate((attribute_embedding_high, highLevel_representation))\n",
    "np.save(\"generateData/Attribute_High_Embedding\", attribute_embedding_high)\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exclusive-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from gensim.models.poincare import PoincareModel\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # 显示时不折叠\n",
    "\n",
    "# 获取每个shop的category向量，并组成category feature矩阵\n",
    "def get_category_matrix():\n",
    "    poincareModel = PoincareModel.load(\"generateData/Category_Hierarchy_Model\")\n",
    "    df_shop = pd.read_csv(\"newData/Shop_data_10.csv\", encoding=\"utf-8\", low_memory=False)\n",
    "    for shop in df_shop.iterrows():\n",
    "        idx = shop[1]['shop_id']\n",
    "        category = shop[1]['small_category']\n",
    "        category_embedding = poincareModel.kv.get_vector(category)\n",
    "        if idx==0:\n",
    "            category_matrix = np.reshape(category_embedding, (1,16))\n",
    "        else:\n",
    "            category_embedding = np.reshape(category_embedding, (1,16))\n",
    "            category_matrix = np.concatenate((category_matrix, category_embedding))\n",
    "    return category_matrix\n",
    "\n",
    "np.save(\"generateData/Category_Embedding\", get_category_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-tower",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
