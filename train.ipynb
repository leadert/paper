{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "romance-virgin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "w_omega \t torch.Size([32, 32])\n",
      "u_omega \t torch.Size([32, 1])\n",
      "w_omega2 \t torch.Size([32, 32])\n",
      "u_omega2 \t torch.Size([32, 1])\n",
      "w_omega3 \t torch.Size([32, 32])\n",
      "u_omega3 \t torch.Size([32, 1])\n",
      "shop_embedding.weight \t torch.Size([21041, 32])\n",
      "conv1.lin.weight \t torch.Size([32, 32])\n",
      "conv1.lin.bias \t torch.Size([32])\n",
      "bn.weight \t torch.Size([32])\n",
      "bn.bias \t torch.Size([32])\n",
      "bn.running_mean \t torch.Size([32])\n",
      "bn.running_var \t torch.Size([32])\n",
      "bn.num_batches_tracked \t torch.Size([])\n",
      "conv2.lin.weight \t torch.Size([32, 32])\n",
      "conv2.lin.bias \t torch.Size([32])\n",
      "lstm1.weight_ih_l0 \t torch.Size([128, 32])\n",
      "lstm1.weight_hh_l0 \t torch.Size([128, 32])\n",
      "lstm1.bias_ih_l0 \t torch.Size([128])\n",
      "lstm1.bias_hh_l0 \t torch.Size([128])\n",
      "lstm2.weight_ih_l0 \t torch.Size([128, 32])\n",
      "lstm2.weight_hh_l0 \t torch.Size([128, 32])\n",
      "lstm2.bias_ih_l0 \t torch.Size([128])\n",
      "lstm2.bias_hh_l0 \t torch.Size([128])\n",
      "fc1.0.weight \t torch.Size([64])\n",
      "fc1.0.bias \t torch.Size([64])\n",
      "fc1.0.running_mean \t torch.Size([64])\n",
      "fc1.0.running_var \t torch.Size([64])\n",
      "fc1.0.num_batches_tracked \t torch.Size([])\n",
      "fc1.1.weight \t torch.Size([32, 64])\n",
      "fc1.1.bias \t torch.Size([32])\n",
      "fc2.0.weight \t torch.Size([64])\n",
      "fc2.0.bias \t torch.Size([64])\n",
      "fc2.0.running_mean \t torch.Size([64])\n",
      "fc2.0.running_var \t torch.Size([64])\n",
      "fc2.0.num_batches_tracked \t torch.Size([])\n",
      "fc2.1.weight \t torch.Size([32, 64])\n",
      "fc2.1.bias \t torch.Size([32])\n",
      "fc3.0.weight \t torch.Size([64])\n",
      "fc3.0.bias \t torch.Size([64])\n",
      "fc3.0.running_mean \t torch.Size([64])\n",
      "fc3.0.running_var \t torch.Size([64])\n",
      "fc3.0.num_batches_tracked \t torch.Size([])\n",
      "fc3.1.weight \t torch.Size([32, 64])\n",
      "fc3.1.bias \t torch.Size([32])\n",
      "fc4.0.weight \t torch.Size([64])\n",
      "fc4.0.bias \t torch.Size([64])\n",
      "fc4.0.running_mean \t torch.Size([64])\n",
      "fc4.0.running_var \t torch.Size([64])\n",
      "fc4.0.num_batches_tracked \t torch.Size([])\n",
      "fc4.1.weight \t torch.Size([32, 64])\n",
      "fc4.1.bias \t torch.Size([32])\n",
      "fc5.0.weight \t torch.Size([32])\n",
      "fc5.0.bias \t torch.Size([32])\n",
      "fc5.0.running_mean \t torch.Size([32])\n",
      "fc5.0.running_var \t torch.Size([32])\n",
      "fc5.0.num_batches_tracked \t torch.Size([])\n",
      "fc5.1.weight \t torch.Size([5, 32])\n",
      "fc5.1.bias \t torch.Size([5])\n",
      "Loading train data....\n",
      "Train Epoch: 1, Batch 1, loss:1.697685\n",
      "*************************Save model successful********************************\n",
      "Train Epoch: 1, Batch 2, loss:1.664871\n",
      "*************************Save model successful********************************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6b92b77bbfdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshop_idxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_poi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_userHistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_userHistoryLength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sum\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\myPaper\\Model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, shop_idxs, data, userId, poiId, userHistory, userHistoryLength)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0muserHistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muserHistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0muserHistory_POI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshop_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muserHistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0muserHistory_POI_packed_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muserHistory_POI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muserHistory_lengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m         \u001b[1;31m# hidden_state集合；userHistory_POI_packed_out是[batch_size*seq_len,embed_dim]的tensor;_[0]是代表每个seq最后一个hiddenState构成的tensor,[1, batch_size, embedding]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0muserHistory_POI_packed_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_n\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muserHistory_POI_packed_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\utils\\rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[1;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[0;32m    232\u001b[0m                       \u001b[1;34m'the trace incorrect for any other combination of lengths.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                       stacklevel=2)\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0msorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Model import Net \n",
    "import os\n",
    "from dataLoader import yield_train_data \n",
    "import torch.nn.functional as F \n",
    "import torch \n",
    "from torch.autograd import Variable\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "\n",
    "# 引入attribute向量\n",
    "attribute_embedding = np.load(\"generateData/Attribute_High_Embedding.npy\") \n",
    "shop_size = attribute_embedding.shape[0]+1    #pad 0\n",
    "# 引入category向量\n",
    "category_embedding = np.load(\"generateData/Category_Embedding.npy\")\n",
    "# shop特征矩阵\n",
    "shop_matrix = np.concatenate((attribute_embedding, category_embedding), axis=1)\n",
    "padLine = np.zeros([1, attribute_embedding.shape[1]+category_embedding.shape[1]])\n",
    "shop_matrix = np.insert(shop_matrix, 0, values=padLine, axis=0)      # pad 0\n",
    "shop_size = shop_matrix.shape[0]\n",
    "\n",
    "\n",
    "struct_matrix = np.load(\"generateData/Spatial_Graph_200m.npy\")\n",
    "edge_index = torch.tensor(struct_matrix, dtype=torch.long).cuda()\n",
    "data = Data(x=shop_matrix, edge_index=edge_index)\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "model = Net(shop_matrix) \n",
    "lr = 0.0005\n",
    "epoches = 20 \n",
    "weight_decay = 1e-5 \n",
    "loss_score = 10000\n",
    "\n",
    "save_path = \"MyNetALL.pkl\"\n",
    "if save_path and not os.path.exists(save_path):\n",
    "    f = open(save_path, \"w\")\n",
    "    f.close()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "# optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=weight_decay) \n",
    "if torch.cuda.is_available(): \n",
    "    model.cuda()\n",
    "\n",
    "# 查看网络中要训练的参数，网络中所有的参数结构\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name)\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epoches): \n",
    "    running_loss = 0.0 \n",
    "    batch_round = 0\n",
    "    for train_data in yield_train_data(500*BATCH_SIZE): \n",
    "        userIndex = train_data[\"userIndex\"]\n",
    "        userHistoryIndex = train_data[\"userHistoryIndex\"] \n",
    "        poiIndex = train_data[\"poiIndex\"]\n",
    "        labelIndex = train_data[\"labelIndex\"]\n",
    "\n",
    "        user = np.array(userIndex, dtype=np.int32)\n",
    "        poi = np.array(poiIndex, dtype=np.int32)\n",
    "        label = np.array(labelIndex, dtype=np.int32)\n",
    "\n",
    "        shop_idxs = Variable(torch.LongTensor(list(range(shop_size))))       # pad 0\n",
    "\n",
    "        batch_iter = user.shape[0] // BATCH_SIZE\n",
    "        for i in range(batch_iter+1):\n",
    "            offset = i * BATCH_SIZE\n",
    "            end = min(offset+BATCH_SIZE, user.shape[0])\n",
    "            if offset == end:\n",
    "                break\n",
    "\n",
    "            batch_user = Variable(torch.LongTensor(user[offset:end]))\n",
    "\n",
    "            batch_userHistoryList = userHistoryIndex[offset:end]\n",
    "            batch_userHistoryLength = []\n",
    "            for idx, element in enumerate(batch_userHistoryList):\n",
    "                batch_userHistoryLength.append(len(element))\n",
    "            batch_userHistoryLength = Variable(torch.LongTensor(batch_userHistoryLength))\n",
    "\n",
    "            max_len = max(len(element) for idx, element in enumerate(batch_userHistoryList))\n",
    "            userHistory = np.zeros([len(batch_userHistoryList), max_len], dtype=np.int32)\n",
    "            for iIndex, element in enumerate(batch_userHistoryList):\n",
    "                for jIndex, sub_element in enumerate(element):\n",
    "                    userHistory[iIndex][jIndex] = sub_element\n",
    "            batch_userHistory = Variable(torch.LongTensor(userHistory))\n",
    "            batch_poi = Variable(torch.LongTensor(poi[offset:end]))\n",
    "            batch_label = Variable(torch.LongTensor(label[offset:end]))\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                shop_idxs, batch_user, batch_userHistory, batch_userHistoryLength, batch_poi, batch_label = shop_idxs.cuda(), batch_user.cuda(), batch_userHistory.cuda(), batch_userHistoryLength.cuda(), batch_poi.cuda(), batch_label.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(shop_idxs, data, batch_user, batch_poi, batch_userHistory, batch_userHistoryLength)\n",
    "            outputs = F.log_softmax(outputs, dim=1)\n",
    "            loss = F.nll_loss(outputs, batch_label, reduction=\"sum\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i%10 == 9:\n",
    "                batch_round += 1\n",
    "                print('Train Epoch: %d, Batch %d, loss:%.6f' % (epoch+1, batch_round, running_loss/(10*BATCH_SIZE)))\n",
    "                if(running_loss<loss_score):\n",
    "                    loss_score = running_loss\n",
    "                    torch.save(model.state_dict(), save_path)\n",
    "                    print(\"*************************Save model successful********************************\")\n",
    "                running_loss = 0\n",
    "            model.train()\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-miller",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
